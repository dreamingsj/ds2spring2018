{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream Aggregation on sliding windows with Spark Streaming\n",
    "\n",
    "In this homework, you will perform window aggregation on json-formatted stream data via Spark Streaming. From the given Kafka data stream which contains users' real-time movie watching data, you will aggregate the recently watched movies into sliding windows according to their release years and write the results to HDFS. This homework consists of the three parts as explained below.\n",
    "\n",
    "This homework is a team assignment, which means that each team is supposed to submit a single copy of the homework. We encourage that the memebers of a same team cooperate with each other. We also assume that you are working on the distributed environment provided via AWS, which consists of one master node and two worker nodes.\n",
    "\n",
    "# Contents Overview:\n",
    "\n",
    "* Part 0: Setup the environment\n",
    "* Part 1: Build a stream application with time-based windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup the environment\n",
    "\n",
    "## Requirements before starting this homework\n",
    "* Python 2.7\n",
    "* Spark 2.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Spark Cluster in standalone mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "/home/ubuntu/spark_scripts/stop_cluster.sh\n",
    "/home/ubuntu/spark_scripts/start_cluster.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether your spark cluster is properly running or not by checking the webpage `master_public_ip_address:8088`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download additional dependencies for Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget http://central.maven.org/maven2/org/apache/spark/spark-streaming-kafka-0-8-assembly_2.11/2.3.0/spark-streaming-kafka-0-8-assembly_2.11-2.3.0.jar -P /home/ubuntu\n",
    "ls /home/ubuntu/*.jar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Build a stream application with time-based windows\n",
    "\n",
    "Now you can start building an application which runs on Spark Streaming. You need to implement the windowed aggregation query given in the document. Fill in the missing part of codes on yourselves to complete the application.\n",
    "\n",
    "Hint: Refer to the previous slides & notebooks and the linked official documentations (https://spark.apache.org/docs/latest/streaming-programming-guide.html) for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "import json\n",
    "\n",
    "findspark.init('/home/ubuntu/spark')\n",
    "\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "# Create a spark and streaming context\n",
    "conf = SparkConf().setAppName(\"Window\").setMaster(\"spark://master:7077\").set(\"spark.jars\", \"/home/ubuntu/spark-streaming-kafka-0-8-assembly_2.11-2.3.0.jar\")\n",
    "spark_context = SparkContext(conf=conf)\n",
    "\n",
    "##############################################################\n",
    "# TODO: Complete this program by filling in the missing parts!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################################################\n",
    "# Start the computation\n",
    "stream_context.start()\n",
    "# await termination for 60 seconds\n",
    "stream_context.awaitTermination(60)\n",
    "stream_context.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your query got killed due to an exception, you may need to stop `stream_context` before you re-execute the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_context.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
